{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install kagglehub\\n\\nimport kagglehub\\n\\n#Download latest version\\npath = kagglehub.dataset_download(\"yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018\")\\n\\nprint(\"Path to dataset files:\", path)\\n\\n%pip install pandas\\n%pip install numpy\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%pip install kagglehub\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "#Download latest version\n",
    "path = kagglehub.dataset_download(\"yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation\n",
    "\n",
    "**In this file we take a look at the dataset focusing on formatting the data for the rest of the work**\n",
    "\n",
    "**The dataset is located here https://www.kaggle.com/datasets/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018/data?select=2013.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start working with the 2013's data. Let's check at first which features it has by printing the one of the rows and then checking the dataset's dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataset are: (6369482, 28)\n",
      "FL_DATE                 object\n",
      "OP_CARRIER              object\n",
      "OP_CARRIER_FL_NUM        int64\n",
      "ORIGIN                  object\n",
      "DEST                    object\n",
      "CRS_DEP_TIME             int64\n",
      "DEP_TIME               float64\n",
      "DEP_DELAY              float64\n",
      "TAXI_OUT               float64\n",
      "WHEELS_OFF             float64\n",
      "WHEELS_ON              float64\n",
      "TAXI_IN                float64\n",
      "CRS_ARR_TIME             int64\n",
      "ARR_TIME               float64\n",
      "ARR_DELAY              float64\n",
      "CANCELLED              float64\n",
      "CANCELLATION_CODE       object\n",
      "DIVERTED               float64\n",
      "CRS_ELAPSED_TIME       float64\n",
      "ACTUAL_ELAPSED_TIME    float64\n",
      "AIR_TIME               float64\n",
      "DISTANCE               float64\n",
      "CARRIER_DELAY          float64\n",
      "WEATHER_DELAY          float64\n",
      "NAS_DELAY              float64\n",
      "SECURITY_DELAY         float64\n",
      "LATE_AIRCRAFT_DELAY    float64\n",
      "Unnamed: 27            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimensions of the dataset are: {np.shape(df)}\")\n",
    "print(df.dtypes) # Let's check what the types of each column are and whether it is correct or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting\n",
    "\n",
    "Our dataset has 6369482 rows and 28 columns.\n",
    "\n",
    "As we can see from above, most numeric features are in float64 format, we ought to standardize the format of all of the numeric features to int64 instead. \n",
    "\n",
    "There is an unnecessary column 'Unnamed: 27' representing nothing and consisting only of NaN values. We will remove the column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_int(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'float64':\n",
    "            # Convert float to int by rounding\n",
    "            df[column] = df[column].round().astype('Int64')\n",
    "    return df\n",
    "\n",
    "df = float_to_int(df)\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 27'], errors='ignore') # Removing the useless column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, there are many times in the military time format : HHMM, we will convert them to a new, 'HH:MM' format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time_format(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NaT\n",
    "    value = int(value)  # In case it's stored as float\n",
    "    hours = value // 100\n",
    "    minutes = value % 100\n",
    "    return f\"{hours:02}:{minutes:02}\"\n",
    "\n",
    "time_columns = ['CRS_DEP_TIME', 'DEP_TIME', 'WHEELS_OFF', 'WHEELS_ON', 'CRS_ARR_TIME', 'ARR_TIME']\n",
    "# Selecting the columns that should be transformed\n",
    "\n",
    "for col in time_columns:\n",
    "    df[col] = df[col].apply(convert_to_time_format) # Applying changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also 2 attributes, which are functionally flags, however are still represented as int64, this is unpreferable in ML applications, we will fix this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CANCELLED and DIVERTED to boolean\n",
    "boolean_columns = ['CANCELLED', 'DIVERTED']\n",
    "for col in boolean_columns:\n",
    "    df[col] = df[col].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we check the results of our formatting changes :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_DATE                object\n",
      "OP_CARRIER             object\n",
      "OP_CARRIER_FL_NUM       int64\n",
      "ORIGIN                 object\n",
      "DEST                   object\n",
      "CRS_DEP_TIME           object\n",
      "DEP_TIME               object\n",
      "DEP_DELAY               Int64\n",
      "TAXI_OUT                Int64\n",
      "WHEELS_OFF             object\n",
      "WHEELS_ON              object\n",
      "TAXI_IN                 Int64\n",
      "CRS_ARR_TIME           object\n",
      "ARR_TIME               object\n",
      "ARR_DELAY               Int64\n",
      "CANCELLED                bool\n",
      "CANCELLATION_CODE      object\n",
      "DIVERTED                 bool\n",
      "CRS_ELAPSED_TIME        Int64\n",
      "ACTUAL_ELAPSED_TIME     Int64\n",
      "AIR_TIME                Int64\n",
      "DISTANCE                Int64\n",
      "CARRIER_DELAY           Int64\n",
      "WEATHER_DELAY           Int64\n",
      "NAS_DELAY               Int64\n",
      "SECURITY_DELAY          Int64\n",
      "LATE_AIRCRAFT_DELAY     Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's considered bad etiquette to maintain composite attributes in databases, for this reason, let's split the FL_DATE attribute into it's smaller components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns added:\n",
      "   MONTH  DAY  YEAR  DAY_OF_WEEK\n",
      "0      1    1  2013            1\n",
      "1      1    1  2013            1\n",
      "2      1    1  2013            1\n",
      "3      1    1  2013            1\n",
      "4      1    1  2013            1\n",
      "\n",
      "Month distribution:\n",
      "MONTH\n",
      "1     7.999379\n",
      "2     7.374948\n",
      "3     8.671223\n",
      "4     8.421297\n",
      "5     8.613605\n",
      "6     8.668539\n",
      "7     8.974403\n",
      "8     8.837783\n",
      "9     8.019585\n",
      "10    8.404828\n",
      "11    7.901679\n",
      "12    8.112732\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Day of week distribution:\n",
      "Monday       14.901353\n",
      "Tuesday      14.600230\n",
      "Wednesday    14.620341\n",
      "Thursday     14.833530\n",
      "Friday       14.946788\n",
      "Saturday     12.050038\n",
      "Sunday       14.047720\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert FL_DATE to datetime if not already\n",
    "df['FL_DATE'] = pd.to_datetime(df['FL_DATE'])\n",
    "\n",
    "# Extract month and day\n",
    "df['MONTH'] = df['FL_DATE'].dt.month\n",
    "df['DAY'] = df['FL_DATE'].dt.day\n",
    "#df['YEAR'] = df['FL_DATE'].dt.year\n",
    "df['DAY_OF_WEEK'] = df['FL_DATE'].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Optional: Drop original FL_DATE column\n",
    "df.drop(columns=['FL_DATE'], inplace=True)\n",
    "\n",
    "# Verify the new columns\n",
    "print(\"New columns added:\")\n",
    "print(df[['MONTH', 'DAY', 'YEAR', 'DAY_OF_WEEK']].head())\n",
    "\n",
    "# Quick statistical overview\n",
    "print(\"\\nMonth distribution:\")\n",
    "print(df['MONTH'].value_counts(normalize=True).sort_index() * 100)\n",
    "\n",
    "print(\"\\nDay of week distribution:\")\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_dist = df['DAY_OF_WEEK'].value_counts(normalize=True).sort_index() * 100\n",
    "day_dist.index = day_names\n",
    "print(day_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for discrepencies\n",
    "\n",
    "Let's start checking for discrepencies, we will start by checking the number of missing (null) values in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER                   0\n",
       "OP_CARRIER_FL_NUM            0\n",
       "ORIGIN                       0\n",
       "DEST                         0\n",
       "CRS_DEP_TIME                 0\n",
       "DEP_TIME                 91681\n",
       "DEP_DELAY                91681\n",
       "TAXI_OUT                 94903\n",
       "WHEELS_OFF               94903\n",
       "WHEELS_ON                98275\n",
       "TAXI_IN                  98275\n",
       "CRS_ARR_TIME                 0\n",
       "ARR_TIME                 98275\n",
       "ARR_DELAY               110172\n",
       "CANCELLED                    0\n",
       "CANCELLATION_CODE      6273470\n",
       "DIVERTED                     0\n",
       "CRS_ELAPSED_TIME             5\n",
       "ACTUAL_ELAPSED_TIME     110172\n",
       "AIR_TIME                110172\n",
       "DISTANCE                     0\n",
       "CARRIER_DELAY          5100205\n",
       "WEATHER_DELAY          5100205\n",
       "NAS_DELAY              5100205\n",
       "SECURITY_DELAY         5100205\n",
       "LATE_AIRCRAFT_DELAY    5100205\n",
       "MONTH                        0\n",
       "DAY                          0\n",
       "YEAR                         0\n",
       "DAY_OF_WEEK                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's alarming that amount of missing values in WHEELS_OFF and WHEELS_ON isn't the same. Let's investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepency is present in : (3372, 30)\n",
      "Discrepency after cancellations is present : (2263, 30)\n",
      "Discrepency after diversions is present : (0, 30)\n"
     ]
    }
   ],
   "source": [
    "# First filter for WHEELS_OFF not missing and WHEELS_ON missing\n",
    "filtered_df = df[\n",
    "    (df['WHEELS_OFF'].notna()) & \n",
    "    (df['WHEELS_ON'].isna())\n",
    "]\n",
    "print(f\"Discrepency is present in : {np.shape(filtered_df)}\")\n",
    "# Additional filter for non-cancelled flights\n",
    "filtered_df = filtered_df[\n",
    "    (filtered_df['CANCELLED'] == False)\n",
    "]\n",
    "print(f\"Discrepency after cancellations is present : {np.shape(filtered_df)}\")\n",
    "\n",
    "filtered_df = filtered_df[\n",
    "    (filtered_df['DIVERTED'] == False)\n",
    "]\n",
    "print(f\"Discrepency after diversions is present : {np.shape(filtered_df)}\")\n",
    "\n",
    "# Set display option to show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue is that there is no data about the flight arriving. It is as if the plane has been in the air for years. However, after applying some filters, we discover, that this only happens when the flight was cancelled or diverted, making the discrepency make sense: the plane took off, but didn't land in the destination airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEP_TIME      91681\n",
       "WHEELS_OFF    94903\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['DEP_TIME', 'WHEELS_OFF']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The number of missing values is not the same for 'DEP_TIME' and 'WHEELS_OFF'. Let's investigate:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3222, 30)\n",
      "(0, 30)\n"
     ]
    }
   ],
   "source": [
    "# First filter\n",
    "filtered_df = df[df['DEP_TIME'].notna() & df['WHEELS_OFF'].isna()]\n",
    "print(np.shape(filtered_df))\n",
    "\n",
    "# Corrected second filter\n",
    "filtered_df2 = filtered_df[(filtered_df['CANCELLED'] == False)]\n",
    "print(np.shape(filtered_df2))\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are cases where airplane has departed but has not touched off the ground. This would mean that airport has been driving on land for years which makes no sense.\n",
    "\n",
    "However, we can see once again, that all of these flights, were cancelled flights. Making the discrepency somewhat logical: the plane started to move, but was unable to take off for whatever reason.\n",
    "\n",
    "### Dealing with the Cancelled and Diverted flights\n",
    "\n",
    "From these discrepencies, we can conclude, that it is more practical to consider these special cases: cancelled and diverted flights, seperately. After all, we cannot apply uniform analysis to normal flights and these exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110172, 30)\n"
     ]
    }
   ],
   "source": [
    "df_cancel = df[\n",
    "    (df['CANCELLED'] == True) | \n",
    "    (df['DIVERTED'] == True)\n",
    "]\n",
    "\n",
    "print(np.shape(df_cancel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this means, that some attributes become useless: the flags and the CANCELLATION_CODE. Just in case, let's first drop the cancelled and diverted flights from the main dataframe and then check if there are any not NaN values in the CANCELLATON_CODE column left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in original dataframe: 6369482\n",
      "Rows after removing cancelled/diverted flights: 6259310\n",
      "Rows with non-NaN cancellation codes: 0\n",
      "\n",
      "Unique non-NaN Cancellation Codes:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# First, drop cancelled and diverted flights\n",
    "df_without_cancelled_diverted = df[\n",
    "    (df['CANCELLED'] == False) & \n",
    "    (df['DIVERTED'] == False)\n",
    "]\n",
    "\n",
    "# Check for non-NaN values in CANCELLATION_CODE\n",
    "non_nan_cancellation_codes = df_without_cancelled_diverted[\n",
    "    df_without_cancelled_diverted['CANCELLATION_CODE'].notna()\n",
    "]\n",
    "\n",
    "# Print results\n",
    "print(\"Total rows in original dataframe:\", len(df))\n",
    "print(\"Rows after removing cancelled/diverted flights:\", len(df_without_cancelled_diverted))\n",
    "print(\"Rows with non-NaN cancellation codes:\", len(non_nan_cancellation_codes))\n",
    "\n",
    "# If you want to see the unique non-NaN cancellation codes\n",
    "print(\"\\nUnique non-NaN Cancellation Codes:\")\n",
    "print(non_nan_cancellation_codes['CANCELLATION_CODE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now safely drop all three of these columns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before dropping: ['OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY', 'CANCELLED', 'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME', 'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY', 'MONTH', 'DAY', 'YEAR', 'DAY_OF_WEEK']\n",
      "Columns after dropping: ['OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY', 'CRS_ELAPSED_TIME', 'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY', 'MONTH', 'DAY', 'YEAR', 'DAY_OF_WEEK']\n",
      "Number of rows before dropping columns: 6259310\n",
      "Number of rows after dropping columns: 6259310\n"
     ]
    }
   ],
   "source": [
    "# Drop CANCELLED, DIVERTED, and CANCELLATION_CODE columns\n",
    "df_cleaned = df_without_cancelled_diverted.drop(\n",
    "    columns=['CANCELLED', 'DIVERTED', 'CANCELLATION_CODE']\n",
    ")\n",
    "\n",
    "# Verify the drop\n",
    "print(\"Columns before dropping:\", list(df_without_cancelled_diverted.columns))\n",
    "print(\"Columns after dropping:\", list(df_cleaned.columns))\n",
    "\n",
    "# Optional: Verify the number of rows remains the same\n",
    "print(\"Number of rows before dropping columns:\", len(df_without_cancelled_diverted))\n",
    "print(\"Number of rows after dropping columns:\", len(df_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if any discrepancies remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER                   0\n",
       "OP_CARRIER_FL_NUM            0\n",
       "ORIGIN                       0\n",
       "DEST                         0\n",
       "CRS_DEP_TIME                 0\n",
       "DEP_TIME                     0\n",
       "DEP_DELAY                    0\n",
       "TAXI_OUT                     0\n",
       "WHEELS_OFF                   0\n",
       "WHEELS_ON                    0\n",
       "TAXI_IN                      0\n",
       "CRS_ARR_TIME                 0\n",
       "ARR_TIME                     0\n",
       "ARR_DELAY                    0\n",
       "CRS_ELAPSED_TIME             0\n",
       "ACTUAL_ELAPSED_TIME          0\n",
       "AIR_TIME                     0\n",
       "DISTANCE                     0\n",
       "CARRIER_DELAY          4990033\n",
       "WEATHER_DELAY          4990033\n",
       "NAS_DELAY              4990033\n",
       "SECURITY_DELAY         4990033\n",
       "LATE_AIRCRAFT_DELAY    4990033\n",
       "MONTH                        0\n",
       "DAY                          0\n",
       "YEAR                         0\n",
       "DAY_OF_WEEK                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemingly the normal flights list is now fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Missing values in the canceled and diverted flights list**\n",
    "\n",
    "There are 5 cases in which 'CRS_ELAPSED_TIME' has a missing value. However, it is possible to calculate it by using columns 'CRS_ARR_TIME' and 'CRS_DEP_TIME' which have no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ORIGIN DEST CRS_DEP_TIME CRS_ARR_TIME  CRS_ELAPSED_TIME  CANCELLED  \\\n",
      "1060779    DEN  MDW        08:30        11:46              <NA>      False   \n",
      "1060780    MDW  DEN        12:25        14:02              <NA>       True   \n",
      "5389021    SNA  DEN        15:00        18:09              <NA>       True   \n",
      "5768225    DEN  BNA        10:22        13:48              <NA>      False   \n",
      "5768226    BNA  DEN        14:28        16:20              <NA>       True   \n",
      "\n",
      "         DIVERTED  \n",
      "1060779      True  \n",
      "1060780     False  \n",
      "5389021     False  \n",
      "5768225      True  \n",
      "5768226     False  \n"
     ]
    }
   ],
   "source": [
    "missing_crs_elapsed_time = df_cancel[df_cancel['CRS_ELAPSED_TIME'].isna()]\n",
    "print(missing_crs_elapsed_time[['ORIGIN','DEST','CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME', 'CANCELLED', 'DIVERTED']])\n",
    "\n",
    "#DENver = UTC(-7) 6 a.m.\n",
    "#BNA Nashville, MDW Chicago = UTC(-6) 7 a.m.\n",
    "#SNA   UTC(-8) 5 a.m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, it is possible to calculate it but we would also need to consider timezone difference so let's check the whole rows.\n",
    "\n",
    "There are five flights which lack the planned elapsed time, to calculate this, we need to consider the departure and arrival airports and their timezones, for example : Chicago and Nashville are in the same timezone and Denver is 1 hour behind them. This means that the first flight's 'CRS_ELAPSED_TIME' should be 97 + 60 = 157. In a similar manner, we calculate for the other four flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRS_DEP_TIME CRS_ARR_TIME  CRS_ELAPSED_TIME\n",
      "1060779        08:30        11:46               136\n",
      "1060780        12:25        14:02               157\n",
      "5768226        14:28        16:20               172\n",
      "5389021        15:00        18:09               129\n",
      "5768225        10:22        13:48               146\n"
     ]
    }
   ],
   "source": [
    "df_cancel.loc[df_cancel.index == 1060779, 'CRS_ELAPSED_TIME'] = 136  # DEN to  MDW\n",
    "df_cancel.loc[df_cancel.index == 1060780, 'CRS_ELAPSED_TIME'] = 157  # MDW to DEN\n",
    "df_cancel.loc[df_cancel.index == 5768226, 'CRS_ELAPSED_TIME'] = 172  # BNA to DEN\n",
    "df_cancel.loc[df_cancel.index == 5389021, 'CRS_ELAPSED_TIME'] = 129  # SNA to DEN\n",
    "df_cancel.loc[df_cancel.index == 5768225, 'CRS_ELAPSED_TIME'] = 146  # DEN to BNA\n",
    "\n",
    "print(df_cancel.loc[[1060779,1060780, 5768226,5389021,5768225], ['CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME']]) # Checking if the missing values have been filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still couple problems within our data. At first, amount of missing values in 'ARR_DELAY' is not equal to amount of missing values in 'ARR_TIME'. Let's investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110172, 30)\n",
      "(11897, 30)\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df_cancel[df_cancel['ARR_TIME'].notna() & df_cancel['ARR_DELAY'].isna()] # Filtering rows where ARR_TIME is not missing, and ARR_DELAY is missing\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(np.shape(df_cancel))\n",
    "print(np.shape(filtered_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fix those missing values by calculating them. We need to do that for 'ARR_DELAY', 'ACTUAL_ELAPSED_TIME' and 'AIR_TIME'.\n",
    "\n",
    "After reviewing the format from the dataframe: we can calculate 'ARR_DELAY' by subtracting 'ARR_TIME' from 'CRS_ARR_TIME' and convert the result into minutes. We can calculate 'ACTUAL_ELAPSED_TIME' by adding 'ARR_DELAY' and 'CRS_ELAPSED_TIME'.  We can calculate 'AIR_TIME' by subtracting 'TAXI_IN' and 'TAXI_OUT' from 'ACTUAL_ELAPSED_TIME'. Let's fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 27)\n"
     ]
    }
   ],
   "source": [
    "filtered_df2 = df_cleaned[df_cleaned['ARR_TIME'].notna() & df_cleaned['ARR_DELAY'].isna()]\n",
    "print(np.shape(filtered_df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ There are no normal flights with this discrepency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11897, 30)\n"
     ]
    }
   ],
   "source": [
    "filtered_df2 = df_cancel[df_cancel['ARR_TIME'].notna() & df_cancel['ARR_DELAY'].isna()]\n",
    "print(np.shape(filtered_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ARR_TIME CRS_ARR_TIME  ARR_DELAY  ACTUAL_ELAPSED_TIME  AIR_TIME\n",
      "231     10:55        10:10         45                  365       355\n",
      "846     14:48        13:10         98                  253       229\n",
      "3149    20:02        16:47        195                  363       328\n",
      "3384    23:58        22:07        111                  328       305\n",
      "3614    15:42        12:36        186                  289       268\n",
      "3739    20:58        14:19        399                  585       548\n",
      "3845    03:12        22:12      -1140                -1068     -1082\n",
      "4014    19:19        13:26        353                  433       409\n",
      "4394    18:44        15:35        189                  276       252\n",
      "4457    15:20        13:17        123                  237       201\n",
      "5571    19:02        18:15         47                  187       164\n",
      "5881    12:54        09:15        219                  399       379\n",
      "6546    10:15        08:20        115                  225       207\n",
      "6647    19:34        18:05         89                  304       280\n",
      "6924    21:58        20:20         98                  313       283\n",
      "     OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST CRS_DEP_TIME DEP_TIME  \\\n",
      "231          WN                113    MCO  LAS        07:50    07:56   \n",
      "846          WN               3915    DEN  LAX        11:35    12:11   \n",
      "3149         EV               3806    EWR  STL        14:59    15:28   \n",
      "3384         EV               4333    EWR  TUL        19:30    19:52   \n",
      "3614         EV               4542    IAH  HSV        10:53    10:47   \n",
      "3739         EV               4627    CLE  DFW        12:13    12:47   \n",
      "3845         EV               4703    IAH  BRO        21:00    23:30   \n",
      "4014         EV               5425    ATL  CRW        12:06    13:31   \n",
      "4394         EV               6128    ORD  CRW        13:08    13:03   \n",
      "4457         EV               6066    DEN  ISN        10:23    10:15   \n",
      "5571         MQ               2927    CSG  DFW        16:55    16:52   \n",
      "5881         MQ               2979    GRR  DFW        07:15    09:47   \n",
      "6546         MQ               4560    DCA  BNA        07:30    07:24   \n",
      "6647         MQ               4525    LGA  XNA        15:30    15:25   \n",
      "6924         MQ               4413    LGA  XNA        17:45    17:40   \n",
      "\n",
      "      DEP_DELAY  TAXI_OUT WHEELS_OFF WHEELS_ON  TAXI_IN CRS_ARR_TIME ARR_TIME  \\\n",
      "231           6         6      08:02     10:51        4        10:10    10:55   \n",
      "846          36        12      12:23     14:36       12        13:10    14:48   \n",
      "3149         29        30      15:58     19:57        5        16:47    20:02   \n",
      "3384         22        20      20:12     23:55        3        22:07    23:58   \n",
      "3614         -6        15      11:02     15:36        6        12:36    15:42   \n",
      "3739         34        30      13:17     20:51        7        14:19    20:58   \n",
      "3845        150         9      23:39     03:07        5        22:12    03:12   \n",
      "4014         85        16      13:47     19:11        8        13:26    19:19   \n",
      "4394         -5        12      13:15     18:32       12        15:35    18:44   \n",
      "4457         -8        31      10:46     15:15        5        13:17    15:20   \n",
      "5571         -3        13      17:05     18:52       10        18:15    19:02   \n",
      "5881        152        15      10:02     12:49        5        09:15    12:54   \n",
      "6546         -6        12      07:36     10:09        6        08:20    10:15   \n",
      "6647         -5        18      15:43     19:28        6        18:05    19:34   \n",
      "6924         -5        23      18:03     21:51        7        20:20    21:58   \n",
      "\n",
      "      ARR_DELAY  CANCELLED CANCELLATION_CODE  DIVERTED  CRS_ELAPSED_TIME  \\\n",
      "231          45      False               NaN      True               320   \n",
      "846          98      False               NaN      True               155   \n",
      "3149        195      False               NaN      True               168   \n",
      "3384        111      False               NaN      True               217   \n",
      "3614        186      False               NaN      True               103   \n",
      "3739        399      False               NaN      True               186   \n",
      "3845      -1140      False               NaN      True                72   \n",
      "4014        353      False               NaN      True                80   \n",
      "4394        189      False               NaN      True                87   \n",
      "4457        123      False               NaN      True               114   \n",
      "5571         47      False               NaN      True               140   \n",
      "5881        219      False               NaN      True               180   \n",
      "6546        115      False               NaN      True               110   \n",
      "6647         89      False               NaN      True               215   \n",
      "6924         98      False               NaN      True               215   \n",
      "\n",
      "      ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  \\\n",
      "231                   365       355      2039           <NA>           <NA>   \n",
      "846                   253       229       862           <NA>           <NA>   \n",
      "3149                  363       328       872           <NA>           <NA>   \n",
      "3384                  328       305      1215           <NA>           <NA>   \n",
      "3614                  289       268       595           <NA>           <NA>   \n",
      "3739                  585       548      1021           <NA>           <NA>   \n",
      "3845                -1068     -1082       308           <NA>           <NA>   \n",
      "4014                  433       409       363           <NA>           <NA>   \n",
      "4394                  276       252       417           <NA>           <NA>   \n",
      "4457                  237       201       576           <NA>           <NA>   \n",
      "5571                  187       164       705           <NA>           <NA>   \n",
      "5881                  399       379       931           <NA>           <NA>   \n",
      "6546                  225       207       562           <NA>           <NA>   \n",
      "6647                  304       280      1147           <NA>           <NA>   \n",
      "6924                  313       283      1147           <NA>           <NA>   \n",
      "\n",
      "      NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  MONTH  DAY  YEAR  \\\n",
      "231        <NA>            <NA>                 <NA>      1    1  2013   \n",
      "846        <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3149       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3384       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3614       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3739       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3845       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "4014       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "4394       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "4457       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "5571       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "5881       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "6546       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "6647       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "6924       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "\n",
      "      DAY_OF_WEEK  \n",
      "231             1  \n",
      "846             1  \n",
      "3149            1  \n",
      "3384            1  \n",
      "3614            1  \n",
      "3739            1  \n",
      "3845            1  \n",
      "4014            1  \n",
      "4394            1  \n",
      "4457            1  \n",
      "5571            1  \n",
      "5881            1  \n",
      "6546            1  \n",
      "6647            1  \n",
      "6924            1  \n"
     ]
    }
   ],
   "source": [
    "def time_to_minutes(time_str):\n",
    "    # Split the time string into hours and minutes\n",
    "    hours, minutes = map(int, time_str.split(':'))\n",
    "    # Return the total minutes after midnight\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "# Creating a copy of filtered_df2 to avoid SettingWithCopyWarning\n",
    "filtered_df2_copy = filtered_df2.copy()\n",
    "\n",
    "# Applying the function to 'ARR_TIME' and 'CRS_ARR_TIME' on the copied DataFrame\n",
    "filtered_df2_copy['ARR_TIME_minutes'] = filtered_df2_copy['ARR_TIME'].apply(time_to_minutes)\n",
    "filtered_df2_copy['CRS_ARR_TIME_minutes'] = filtered_df2_copy['CRS_ARR_TIME'].apply(time_to_minutes)\n",
    "\n",
    "# Calculating 'ARR_DELAY' as the difference between 'ARR_TIME' and 'CRS_ARR_TIME'\n",
    "filtered_df2_copy['ARR_DELAY'] = filtered_df2_copy['ARR_TIME_minutes'] - filtered_df2_copy['CRS_ARR_TIME_minutes']\n",
    "\n",
    "# Calculating 'ACTUAL_ELAPSED_TIME' by adding 'ARR_DELAY' to 'CRS_ELAPSED_TIME'\n",
    "filtered_df2_copy['ACTUAL_ELAPSED_TIME'] = filtered_df2_copy['ARR_DELAY'] + filtered_df2_copy['CRS_ELAPSED_TIME']\n",
    "\n",
    "# Calculating 'AIR_TIME' by subtracting 'TAXI_IN' and 'TAXI_OUT' from 'ACTUAL_ELAPSED_TIME'\n",
    "filtered_df2_copy['AIR_TIME'] = filtered_df2_copy['ACTUAL_ELAPSED_TIME'] - filtered_df2_copy['TAXI_IN'] - filtered_df2_copy['TAXI_OUT']\n",
    "\n",
    "# Dropping the temporary columns 'ARR_TIME_minutes' and 'CRS_ARR_TIME_minutes'\n",
    "filtered_df2_copy.drop(['ARR_TIME_minutes', 'CRS_ARR_TIME_minutes'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(filtered_df2_copy[['ARR_TIME', 'CRS_ARR_TIME', 'ARR_DELAY', 'ACTUAL_ELAPSED_TIME', 'AIR_TIME']].head(15))\n",
    "print(filtered_df2_copy.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As visible from row with index 3845, this solution does not account for the cases in which plane arrived after midnight but was scheduled to arrive before midnight. After having a look on the data, it can be concluded that investigating those anomalies is tricky. One way is to determine from whole data how long the longest flights in the dataset took. Let's take a look at the most extreme 'CRS_ELAPSED_TIME' and 'ACTUAL_ELAPSED_TIME' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        OP_CARRIER  OP_CARRIER_FL_NUM  CRS_ELAPSED_TIME ARR_TIME CRS_ARR_TIME\n",
      "664866          UA                 15               660      NaT        19:41\n",
      "1427297         UA                145               645      NaT        17:35\n",
      "1798081         UA                 15               645    22:44        18:15\n",
      "1070558         UA                145               645      NaT        18:35\n",
      "4736902         UA                 15               644    19:23        18:13\n",
      "3700524         UA                 15               636      NaT        18:01\n",
      "3277255         UA                 15               636    21:49        18:01\n",
      "3199142         UA                 15               636    21:21        18:01\n",
      "3700543         UA                145               627      NaT        17:27\n",
      "2566242         DL                837               590    18:48        14:40\n",
      "4736901         UA                 14               580    14:23        11:55\n",
      "3700523         UA                 14               578      NaT        11:48\n",
      "3199141         UA                 14               578    17:37        11:48\n",
      "1427250         UA                 14               577      NaT        12:02\n",
      "613124          UA                 14               574      NaT        12:02\n",
      "3700542         UA                144               565      NaT        11:30\n",
      "2984812         AA                 73               550    22:43        18:35\n",
      "4204602         AA                 73               550    19:52        18:35\n",
      "1064262         UA                144               550      NaT        11:20\n",
      "2942772         AA                 73               550      NaT        18:35\n"
     ]
    }
   ],
   "source": [
    "# Sorting the dataframe by 'CRS_ELAPSED_TIME' in descending order\n",
    "max_elapsed_time_row = df_cancel.sort_values(by='CRS_ELAPSED_TIME', ascending=False).head(20)\n",
    "\n",
    "# Display the row with the maximum elapsed time\n",
    "print(max_elapsed_time_row[[ 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'CRS_ELAPSED_TIME', 'ARR_TIME', 'CRS_ARR_TIME']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By estimating that flights that are going to be seen as an anomaly won't take over 12 hours (720 minutes) it is possible to classify a case as an anomaly (the flight was supposed to land before midnight but landed after midnight) if 'CRS_ARR_TIME' is from 12:00 to 23:59 and if 'ARR_TIME' is from 00:00 to 11:59. If both of those conditions are true then we should deal by calculating 'ARR_DELAY' in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ARR_TIME CRS_ARR_TIME  ARR_DELAY  ACTUAL_ELAPSED_TIME  AIR_TIME\n",
      "231     10:55        10:10         45                  365       355\n",
      "846     14:48        13:10         98                  253       229\n",
      "3149    20:02        16:47        195                  363       328\n",
      "3384    23:58        22:07        111                  328       305\n",
      "3614    15:42        12:36        186                  289       268\n",
      "3739    20:58        14:19        399                  585       548\n",
      "3845    03:12        22:12        300                  372       358\n",
      "4014    19:19        13:26        353                  433       409\n",
      "4394    18:44        15:35        189                  276       252\n",
      "4457    15:20        13:17        123                  237       201\n",
      "5571    19:02        18:15         47                  187       164\n",
      "5881    12:54        09:15        219                  399       379\n",
      "6546    10:15        08:20        115                  225       207\n",
      "6647    19:34        18:05         89                  304       280\n",
      "6924    21:58        20:20         98                  313       283\n",
      "     OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST CRS_DEP_TIME DEP_TIME  \\\n",
      "231          WN                113    MCO  LAS        07:50    07:56   \n",
      "846          WN               3915    DEN  LAX        11:35    12:11   \n",
      "3149         EV               3806    EWR  STL        14:59    15:28   \n",
      "3384         EV               4333    EWR  TUL        19:30    19:52   \n",
      "3614         EV               4542    IAH  HSV        10:53    10:47   \n",
      "3739         EV               4627    CLE  DFW        12:13    12:47   \n",
      "3845         EV               4703    IAH  BRO        21:00    23:30   \n",
      "4014         EV               5425    ATL  CRW        12:06    13:31   \n",
      "4394         EV               6128    ORD  CRW        13:08    13:03   \n",
      "4457         EV               6066    DEN  ISN        10:23    10:15   \n",
      "5571         MQ               2927    CSG  DFW        16:55    16:52   \n",
      "5881         MQ               2979    GRR  DFW        07:15    09:47   \n",
      "6546         MQ               4560    DCA  BNA        07:30    07:24   \n",
      "6647         MQ               4525    LGA  XNA        15:30    15:25   \n",
      "6924         MQ               4413    LGA  XNA        17:45    17:40   \n",
      "\n",
      "      DEP_DELAY  TAXI_OUT WHEELS_OFF WHEELS_ON  TAXI_IN CRS_ARR_TIME ARR_TIME  \\\n",
      "231           6         6      08:02     10:51        4        10:10    10:55   \n",
      "846          36        12      12:23     14:36       12        13:10    14:48   \n",
      "3149         29        30      15:58     19:57        5        16:47    20:02   \n",
      "3384         22        20      20:12     23:55        3        22:07    23:58   \n",
      "3614         -6        15      11:02     15:36        6        12:36    15:42   \n",
      "3739         34        30      13:17     20:51        7        14:19    20:58   \n",
      "3845        150         9      23:39     03:07        5        22:12    03:12   \n",
      "4014         85        16      13:47     19:11        8        13:26    19:19   \n",
      "4394         -5        12      13:15     18:32       12        15:35    18:44   \n",
      "4457         -8        31      10:46     15:15        5        13:17    15:20   \n",
      "5571         -3        13      17:05     18:52       10        18:15    19:02   \n",
      "5881        152        15      10:02     12:49        5        09:15    12:54   \n",
      "6546         -6        12      07:36     10:09        6        08:20    10:15   \n",
      "6647         -5        18      15:43     19:28        6        18:05    19:34   \n",
      "6924         -5        23      18:03     21:51        7        20:20    21:58   \n",
      "\n",
      "      ARR_DELAY  CANCELLED CANCELLATION_CODE  DIVERTED  CRS_ELAPSED_TIME  \\\n",
      "231          45      False               NaN      True               320   \n",
      "846          98      False               NaN      True               155   \n",
      "3149        195      False               NaN      True               168   \n",
      "3384        111      False               NaN      True               217   \n",
      "3614        186      False               NaN      True               103   \n",
      "3739        399      False               NaN      True               186   \n",
      "3845        300      False               NaN      True                72   \n",
      "4014        353      False               NaN      True                80   \n",
      "4394        189      False               NaN      True                87   \n",
      "4457        123      False               NaN      True               114   \n",
      "5571         47      False               NaN      True               140   \n",
      "5881        219      False               NaN      True               180   \n",
      "6546        115      False               NaN      True               110   \n",
      "6647         89      False               NaN      True               215   \n",
      "6924         98      False               NaN      True               215   \n",
      "\n",
      "      ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  \\\n",
      "231                   365       355      2039           <NA>           <NA>   \n",
      "846                   253       229       862           <NA>           <NA>   \n",
      "3149                  363       328       872           <NA>           <NA>   \n",
      "3384                  328       305      1215           <NA>           <NA>   \n",
      "3614                  289       268       595           <NA>           <NA>   \n",
      "3739                  585       548      1021           <NA>           <NA>   \n",
      "3845                  372       358       308           <NA>           <NA>   \n",
      "4014                  433       409       363           <NA>           <NA>   \n",
      "4394                  276       252       417           <NA>           <NA>   \n",
      "4457                  237       201       576           <NA>           <NA>   \n",
      "5571                  187       164       705           <NA>           <NA>   \n",
      "5881                  399       379       931           <NA>           <NA>   \n",
      "6546                  225       207       562           <NA>           <NA>   \n",
      "6647                  304       280      1147           <NA>           <NA>   \n",
      "6924                  313       283      1147           <NA>           <NA>   \n",
      "\n",
      "      NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  MONTH  DAY  YEAR  \\\n",
      "231        <NA>            <NA>                 <NA>      1    1  2013   \n",
      "846        <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3149       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3384       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3614       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3739       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "3845       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "4014       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "4394       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "4457       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "5571       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "5881       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "6546       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "6647       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "6924       <NA>            <NA>                 <NA>      1    1  2013   \n",
      "\n",
      "      DAY_OF_WEEK  \n",
      "231             1  \n",
      "846             1  \n",
      "3149            1  \n",
      "3384            1  \n",
      "3614            1  \n",
      "3739            1  \n",
      "3845            1  \n",
      "4014            1  \n",
      "4394            1  \n",
      "4457            1  \n",
      "5571            1  \n",
      "5881            1  \n",
      "6546            1  \n",
      "6647            1  \n",
      "6924            1  \n"
     ]
    }
   ],
   "source": [
    "filtered_df2_copy['ARR_TIME_minutes'] = filtered_df2_copy['ARR_TIME'].apply(time_to_minutes)\n",
    "filtered_df2_copy['CRS_ARR_TIME_minutes'] = filtered_df2_copy['CRS_ARR_TIME'].apply(time_to_minutes)\n",
    "\n",
    "# Identifying rows with anomaly conditions\n",
    "anomalies = (filtered_df2_copy['CRS_ARR_TIME_minutes'] >= 720) & (filtered_df2_copy['ARR_TIME_minutes'] < 720)\n",
    "\n",
    "# Adding 1440 minutes to 'ARR_TIME_minutes' for anomalies (arrived after midnight but was not supposed to)\n",
    "filtered_df2_copy.loc[anomalies, 'ARR_TIME_minutes'] += 1440\n",
    "\n",
    "# Recalculating 'ARR_DELAY' as the difference between 'ARR_TIME' and 'CRS_ARR_TIME'\n",
    "filtered_df2_copy['ARR_DELAY'] = filtered_df2_copy['ARR_TIME_minutes'] - filtered_df2_copy['CRS_ARR_TIME_minutes']\n",
    "\n",
    "# Recalculating 'ACTUAL_ELAPSED_TIME' by adding 'ARR_DELAY' to 'CRS_ELAPSED_TIME'\n",
    "filtered_df2_copy['ACTUAL_ELAPSED_TIME'] = filtered_df2_copy['ARR_DELAY'] + filtered_df2_copy['CRS_ELAPSED_TIME']\n",
    "\n",
    "# Recalculating 'AIR_TIME' by subtracting 'TAXI_IN' and 'TAXI_OUT' from 'ACTUAL_ELAPSED_TIME'\n",
    "filtered_df2_copy['AIR_TIME'] = filtered_df2_copy['ACTUAL_ELAPSED_TIME'] - filtered_df2_copy['TAXI_IN'] - filtered_df2_copy['TAXI_OUT']\n",
    "\n",
    "# Dropping the temporary columns 'ARR_TIME_minutes' and 'CRS_ARR_TIME_minutes'\n",
    "filtered_df2_copy.drop(['ARR_TIME_minutes', 'CRS_ARR_TIME_minutes'], axis=1, inplace=True)\n",
    "\n",
    "# Print the updated dataframe with the calculated columns\n",
    "print(filtered_df2_copy[['ARR_TIME', 'CRS_ARR_TIME', 'ARR_DELAY', 'ACTUAL_ELAPSED_TIME', 'AIR_TIME']].head(15))\n",
    "print(filtered_df2_copy.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply the changes to the dataset we want to continue working with (df_cleaned2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ARR_DELAY  ACTUAL_ELAPSED_TIME  AIR_TIME\n",
      "231          45                  365       355\n",
      "846          98                  253       229\n",
      "2878       <NA>                 <NA>      <NA>\n",
      "2973       <NA>                 <NA>      <NA>\n",
      "3130       <NA>                 <NA>      <NA>\n",
      "3131       <NA>                 <NA>      <NA>\n",
      "3132       <NA>                 <NA>      <NA>\n",
      "3149        195                  363       328\n",
      "3245       <NA>                 <NA>      <NA>\n",
      "3310       <NA>                 <NA>      <NA>\n",
      "3322       <NA>                 <NA>      <NA>\n",
      "3325       <NA>                 <NA>      <NA>\n",
      "3367       <NA>                 <NA>      <NA>\n",
      "3384        111                  328       305\n",
      "3422       <NA>                 <NA>      <NA>\n",
      "OP_CARRIER                EV\n",
      "OP_CARRIER_FL_NUM       4703\n",
      "ORIGIN                   IAH\n",
      "DEST                     BRO\n",
      "CRS_DEP_TIME           21:00\n",
      "DEP_TIME               23:30\n",
      "DEP_DELAY                150\n",
      "TAXI_OUT                   9\n",
      "WHEELS_OFF             23:39\n",
      "WHEELS_ON              03:07\n",
      "TAXI_IN                    5\n",
      "CRS_ARR_TIME           22:12\n",
      "ARR_TIME               03:12\n",
      "ARR_DELAY                300\n",
      "CANCELLED              False\n",
      "CANCELLATION_CODE        NaN\n",
      "DIVERTED                True\n",
      "CRS_ELAPSED_TIME          72\n",
      "ACTUAL_ELAPSED_TIME      372\n",
      "AIR_TIME                 358\n",
      "DISTANCE                 308\n",
      "CARRIER_DELAY           <NA>\n",
      "WEATHER_DELAY           <NA>\n",
      "NAS_DELAY               <NA>\n",
      "SECURITY_DELAY          <NA>\n",
      "LATE_AIRCRAFT_DELAY     <NA>\n",
      "MONTH                      1\n",
      "DAY                        1\n",
      "YEAR                    2013\n",
      "DAY_OF_WEEK                1\n",
      "Name: 3845, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Using .loc[] to ensure we are modifying the original DataFrame correctly\n",
    "df_cancel.loc[df_cancel['ARR_DELAY'].isna(), 'ARR_DELAY'] = filtered_df2_copy['ARR_DELAY']\n",
    "df_cancel.loc[df_cancel['ACTUAL_ELAPSED_TIME'].isna(), 'ACTUAL_ELAPSED_TIME'] = filtered_df2_copy['ACTUAL_ELAPSED_TIME']\n",
    "df_cancel.loc[df_cancel['AIR_TIME'].isna(), 'AIR_TIME'] = filtered_df2_copy['AIR_TIME']\n",
    "\n",
    "# Checking if it worked\n",
    "print(df_cancel[['ARR_DELAY', 'ACTUAL_ELAPSED_TIME', 'AIR_TIME']].head(15))\n",
    "print(df_cancel.loc[3845])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are only few things left to check - whether amount of missing values in 'CANCELLATION_CODE' makes sense and whether the amounts of missing values in 'CARRIER_DELAY',\n",
    "'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY' and 'LATE_AIRCRAFT_DELAY' make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OP_CARRIER                   0\n",
       "OP_CARRIER_FL_NUM            0\n",
       "ORIGIN                       0\n",
       "DEST                         0\n",
       "CRS_DEP_TIME                 0\n",
       "DEP_TIME                     0\n",
       "DEP_DELAY                    0\n",
       "TAXI_OUT                     0\n",
       "WHEELS_OFF                   0\n",
       "WHEELS_ON                    0\n",
       "TAXI_IN                      0\n",
       "CRS_ARR_TIME                 0\n",
       "ARR_TIME                     0\n",
       "ARR_DELAY                    0\n",
       "CRS_ELAPSED_TIME             0\n",
       "ACTUAL_ELAPSED_TIME          0\n",
       "AIR_TIME                     0\n",
       "DISTANCE                     0\n",
       "CARRIER_DELAY          4990033\n",
       "WEATHER_DELAY          4990033\n",
       "NAS_DELAY              4990033\n",
       "SECURITY_DELAY         4990033\n",
       "LATE_AIRCRAFT_DELAY    4990033\n",
       "MONTH                        0\n",
       "DAY                          0\n",
       "YEAR                         0\n",
       "DAY_OF_WEEK                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cancelled flights: 96012\n",
      "Number of Diverted flights: 14160\n"
     ]
    }
   ],
   "source": [
    "# Counting how many times a flight was not cancelled\n",
    "cancelled_count = df_cancel[df_cancel['CANCELLED'] == 1].shape[0]\n",
    "diverted_count = df_cancel[df_cancel['DIVERTED'] == 1].shape[0]\n",
    "\n",
    "print(f'Number of Cancelled flights: {cancelled_count}')\n",
    "print(f'Number of Diverted flights: {diverted_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding attributes\n",
    "\n",
    "### Rush Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Ensuring 'CRS_DEP_TIME' is in the correct string format and extracting the hour\\ndf_cleaned['DEP_Hour'] = df_cleaned['CRS_DEP_TIME'].str.split(':').str[0].astype(int)\\n\\n# Plotting the distribution of DEP_Hour\\nplt.figure(figsize=(12, 6))\\nax = sns.histplot(\\n    df_cleaned['DEP_Hour'], \\n    bins=range(25), \\n    kde=False, \\n    color='blue', \\n    shrink=0.9  # Adjusts the bar width\\n)\\n\\n# Adding text annotations inside each bar, vertically, only for counts > 100000\\nfor p in ax.patches:\\n    count = int(p.get_height())  # Getting the height of each bar\\n    if count > 100000:  # Only annotating bars with counts over 100000\\n        ax.annotate(\\n            f'{count}',\\n            (p.get_x() + p.get_width() / 2., count / 2),  # Centering inside the bar\\n            ha='center', va='center', fontsize=10, color='white', weight='bold',\\n            rotation=90  # Makes the text vertical\\n        )\\n\\n\\nplt.title('Distribution of Scheduled Departure Hours (CRS_DEP_TIME)', fontsize=14)\\nplt.xlabel('Hour of Day (24-Hour Clock)', fontsize=12)\\nplt.ylabel('Frequency', fontsize=12)\\nplt.xticks(range(0, 25))\\nplt.grid(axis='y', linestyle='--', alpha=0.7)\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensuring 'CRS_DEP_TIME' is in the correct string format and extracting the hour\n",
    "df_cleaned['DEP_Hour'] = df_cleaned['CRS_DEP_TIME'].str.split(':').str[0].astype(int)\n",
    "\n",
    "# Plotting the distribution of DEP_Hour\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.histplot(\n",
    "    df_cleaned['DEP_Hour'], \n",
    "    bins=range(25), \n",
    "    kde=False, \n",
    "    color='blue', \n",
    "    shrink=0.9  # Adjusts the bar width\n",
    ")\n",
    "\n",
    "# Adding text annotations inside each bar, vertically, only for counts > 100000\n",
    "for p in ax.patches:\n",
    "    count = int(p.get_height())  # Getting the height of each bar\n",
    "    if count > 100000:  # Only annotating bars with counts over 100000\n",
    "        ax.annotate(\n",
    "            f'{count}',\n",
    "            (p.get_x() + p.get_width() / 2., count / 2),  # Centering inside the bar\n",
    "            ha='center', va='center', fontsize=10, color='white', weight='bold',\n",
    "            rotation=90  # Makes the text vertical\n",
    "        )\n",
    "\n",
    "\n",
    "plt.title('Distribution of Scheduled Departure Hours (CRS_DEP_TIME)', fontsize=14)\n",
    "plt.xlabel('Hour of Day (24-Hour Clock)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(range(0, 25))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, it is possible to see that the distribution of planned departure time is very similar from 6:00 to 19:59. Timespan 17:00 - 17:59 had the most planned departures (446554) and it was closely followed by timespan 8:00 - 8:59 (442666 planned departures). Third most popular timespan for planned departures was 7:00 - 7:59 with 432303 planned departures. Let's classify only timespans 17:00 - 17:59 and 8:00 - 8:59 as rush hours for departures and later use this information to see if departure time at rush hour caused bigger delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a binary feature 'DEP_Rush_Hour' that has value 1 when scheduled departure time was in timespans 8:00 - 8:59 or 17:00 - 17:59. We can use previously defined feature 'DEP_Hour' to define this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rush_Hour = [8, 17]\n",
    "#Rush_Hour.__contains__(x)\n",
    "#df_cleaned['DEP_Rush_Hour'] = df_cleaned['DEP_Hour'].apply(lambda x: 1 if x. == 8 or x == 17 else 0)\n",
    "#df_cleaned2[['DEP_Hour', 'DEP_Rush_Hour']].head(20) # Checking if it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's repeat the process for arrivals but now focus on actual arrival times, not scheduled arrival times. Reasoning for focusing on actual arrival times is that results from further analysis will be more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Creating the 'ARR_Hour' feature, extract hour only for non-NaT values\\ndf_cleaned2['ARR_Hour'] = df_cleaned2['ARR_TIME'].apply(lambda x: int(x.split(':')[0]) if pd.notna(x) else pd.NaT)\\n\\n\\n\\n# Plotting the distribution of DEP_Hour\\nplt.figure(figsize=(12, 6))\\nax = sns.histplot(\\n    df_cleaned2['ARR_Hour'], \\n    bins=range(25), \\n    kde=False, \\n    color='blue', \\n    shrink=0.9  # Adjusts the bar width\\n)\\n\\n# Adding text annotations inside each bar, vertically, only for counts > 100000\\nfor p in ax.patches:\\n    count = int(p.get_height())  # Getting the height of each bar\\n    if count > 100000:  # Only annotating bars with counts over 100000\\n        ax.annotate(\\n            f'{count}',\\n            (p.get_x() + p.get_width() / 2., count / 2),  # Centering inside the bar\\n            ha='center', va='center', fontsize=10, color='white', weight='bold',\\n            rotation=90  # Makes the text vertical\\n        )\\n\\n\\nplt.title('Distribution of Actual Arrival Hours (ARR_TIME)', fontsize=14)\\nplt.xlabel('Hour of Day (24-Hour Clock)', fontsize=12)\\nplt.ylabel('Frequency', fontsize=12)\\nplt.xticks(range(0, 25))\\nplt.grid(axis='y', linestyle='--', alpha=0.7)\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Creating the 'ARR_Hour' feature, extract hour only for non-NaT values\n",
    "df_cleaned2['ARR_Hour'] = df_cleaned2['ARR_TIME'].apply(lambda x: int(x.split(':')[0]) if pd.notna(x) else pd.NaT)\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the distribution of DEP_Hour\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.histplot(\n",
    "    df_cleaned2['ARR_Hour'], \n",
    "    bins=range(25), \n",
    "    kde=False, \n",
    "    color='blue', \n",
    "    shrink=0.9  # Adjusts the bar width\n",
    ")\n",
    "\n",
    "# Adding text annotations inside each bar, vertically, only for counts > 100000\n",
    "for p in ax.patches:\n",
    "    count = int(p.get_height())  # Getting the height of each bar\n",
    "    if count > 100000:  # Only annotating bars with counts over 100000\n",
    "        ax.annotate(\n",
    "            f'{count}',\n",
    "            (p.get_x() + p.get_width() / 2., count / 2),  # Centering inside the bar\n",
    "            ha='center', va='center', fontsize=10, color='white', weight='bold',\n",
    "            rotation=90  # Makes the text vertical\n",
    "        )\n",
    "\n",
    "\n",
    "plt.title('Distribution of Actual Arrival Hours (ARR_TIME)', fontsize=14)\n",
    "plt.xlabel('Hour of Day (24-Hour Clock)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(range(0, 25))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6259310.0</td>\n",
       "      <td>6259310.0</td>\n",
       "      <td>6259310.0</td>\n",
       "      <td>6259310.0</td>\n",
       "      <td>6259310.0</td>\n",
       "      <td>6259310.0</td>\n",
       "      <td>6259310.0</td>\n",
       "      <td>6259310.0</td>\n",
       "      <td>1269277.0</td>\n",
       "      <td>1269277.0</td>\n",
       "      <td>1269277.0</td>\n",
       "      <td>1269277.0</td>\n",
       "      <td>1269277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.684819</td>\n",
       "      <td>15.592381</td>\n",
       "      <td>6.772477</td>\n",
       "      <td>6.010872</td>\n",
       "      <td>132.994205</td>\n",
       "      <td>129.320258</td>\n",
       "      <td>106.9554</td>\n",
       "      <td>764.57842</td>\n",
       "      <td>16.652706</td>\n",
       "      <td>2.343187</td>\n",
       "      <td>13.729758</td>\n",
       "      <td>0.081661</td>\n",
       "      <td>23.868734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.567039</td>\n",
       "      <td>9.033458</td>\n",
       "      <td>4.710094</td>\n",
       "      <td>38.052002</td>\n",
       "      <td>72.169934</td>\n",
       "      <td>71.66801</td>\n",
       "      <td>69.769858</td>\n",
       "      <td>585.970127</td>\n",
       "      <td>43.581631</td>\n",
       "      <td>17.025016</td>\n",
       "      <td>27.65401</td>\n",
       "      <td>2.627572</td>\n",
       "      <td>41.037532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>991.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1975.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>4983.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>1182.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DEP_DELAY   TAXI_OUT    TAXI_IN  ARR_DELAY  CRS_ELAPSED_TIME  \\\n",
       "count  6259310.0  6259310.0  6259310.0  6259310.0         6259310.0   \n",
       "mean    9.684819  15.592381   6.772477   6.010872        132.994205   \n",
       "std    35.567039   9.033458   4.710094  38.052002         72.169934   \n",
       "min       -171.0        1.0        1.0     -153.0              20.0   \n",
       "25%         -5.0       10.0        4.0      -12.0              81.0   \n",
       "50%         -1.0       13.0        6.0       -3.0             114.0   \n",
       "75%          9.0       18.0        8.0       10.0             163.0   \n",
       "max       1975.0      237.0      346.0     1983.0             700.0   \n",
       "\n",
       "       ACTUAL_ELAPSED_TIME   AIR_TIME    DISTANCE  CARRIER_DELAY  \\\n",
       "count            6259310.0  6259310.0   6259310.0      1269277.0   \n",
       "mean            129.320258   106.9554   764.57842      16.652706   \n",
       "std               71.66801  69.769858  585.970127      43.581631   \n",
       "min                   11.0        5.0        31.0            0.0   \n",
       "25%                   78.0       57.0       341.0            0.0   \n",
       "50%                  110.0       87.0       596.0            1.0   \n",
       "75%                  159.0      136.0       991.0           16.0   \n",
       "max                  738.0      695.0      4983.0         1975.0   \n",
       "\n",
       "       WEATHER_DELAY  NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  \n",
       "count      1269277.0  1269277.0       1269277.0            1269277.0  \n",
       "mean        2.343187  13.729758        0.081661            23.868734  \n",
       "std        17.025016   27.65401        2.627572            41.037532  \n",
       "min              0.0        0.0             0.0                  0.0  \n",
       "25%              0.0        0.0             0.0                  0.0  \n",
       "50%              0.0        3.0             0.0                  7.0  \n",
       "75%              0.0       18.0             0.0                 31.0  \n",
       "max           1591.0     1287.0           573.0               1182.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting only relevant numerical features for summary statistics\n",
    "numerical_features = ['DEP_DELAY', 'TAXI_OUT', 'TAXI_IN', 'ARR_DELAY', 'CRS_ELAPSED_TIME', 'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', \n",
    "    'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']\n",
    "\n",
    "# Generating descriptive statistics for numerical features\n",
    "numerical_stats = df_cleaned[numerical_features].describe()\n",
    "\n",
    "# Displaying the statistics\n",
    "numerical_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "**The data formatting is done, we will save the two dataframes into files and utilize them in the next notebooks on EDA and ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_csv('df_cleaned.csv', index=False)\n",
    "df_cancel.to_csv('df_cancel.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
