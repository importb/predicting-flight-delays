{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "In this notebook we implement a model to study the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('df_cleaned.csv')\n",
    "df_cancel = pd.read_csv('df_cancel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANCELLED\n",
      "False    6273470\n",
      "True       96012\n",
      "Name: count, dtype: int64\n",
      "DIVERTED\n",
      "False    6355322\n",
      "True       14160\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add the missing columns to the regular flights dataframe\n",
    "df['CANCELLED'] = False\n",
    "df['CANCELLATION_CODE'] = np.nan  # or '' depending on your preference\n",
    "df['DIVERTED'] = False\n",
    "\n",
    "# Ensure column order and types match\n",
    "# You might need to adjust dtypes to match\n",
    "df['CANCELLED'] = df['CANCELLED'].astype(bool)\n",
    "df['DIVERTED'] = df['DIVERTED'].astype(bool)\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_flights = pd.concat([df, df_cancel], ignore_index=True)\n",
    "\n",
    "# Optional: Verify the combination\n",
    "print(combined_flights['CANCELLED'].value_counts())\n",
    "print(combined_flights['DIVERTED'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we format the time attributes hh:mm into minutes from midnight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:34\n"
     ]
    }
   ],
   "source": [
    "print(combined_flights.iloc[39]['DEP_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874.0\n"
     ]
    }
   ],
   "source": [
    "def time_to_minutes(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    hours, minutes = map(int, time_str.split(\":\"))\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "time_columns = ['CRS_DEP_TIME', 'DEP_TIME', 'WHEELS_OFF', 'WHEELS_ON', 'CRS_ARR_TIME', 'ARR_TIME']\n",
    "\n",
    "# Combine approaches\n",
    "for col in time_columns:\n",
    "    # Minutes since midnight\n",
    "    combined_flights[col] = combined_flights[col].apply(time_to_minutes)\n",
    "\n",
    "print(combined_flights.iloc[39]['DEP_TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we decide what attribute we will try to predict and what attributes should be available for the prediction.\n",
    "\n",
    "For this, lets once again review the attributes list:\n",
    "\n",
    "<font color='green'> **Green colored attributes are available before the flight**</font>\n",
    " \n",
    "<font color='lightblue'> **Blue colored attributes signify attributes that we can or want to predict**   </font> \n",
    "\n",
    "- <font color='green'>OP_CARRIER        </font> \n",
    "- <font color='green'>OP_CARRIER_FL_NUM </font> \n",
    "- <font color='green'>ORIGIN            </font> \n",
    "- <font color='green'>DEST              </font> \n",
    "- <font color='green'>CRS_DEP_TIME      </font> \n",
    "- <font color='green'>CRS_ARR_TIME      </font> \n",
    "- <font color='green'>CRS_ELAPSED_TIME  </font> \n",
    "- <font color='green'>DISTANCE          </font> \n",
    "- <font color='green'>MONTH             </font> \n",
    "- <font color='green'>DAY               </font> \n",
    "- <font color='green'>YEAR              </font> \n",
    "- <font color='green'>DAY_OF_WEEK       </font> \n",
    "- DEP_TIME               \n",
    "- DEP_DELAY              \n",
    "- TAXI_OUT               \n",
    "- WHEELS_OFF             \n",
    "- WHEELS_ON              \n",
    "- TAXI_IN                \n",
    "- ARR_TIME               \n",
    "- <font color='lightblue'>ARR_DELAY</font>\n",
    "- ACTUAL_ELAPSED_TIME    \n",
    "- AIR_TIME               \n",
    "- CARRIER_DELAY          \n",
    "- WEATHER_DELAY          \n",
    "- NAS_DELAY              \n",
    "- SECURITY_DELAY         \n",
    "- LATE_AIRCRAFT_DELAY    \n",
    "- <font color='lightblue'> CANCELLED        </font>     \n",
    "- <font color='lightblue'> CANCELLATION_CODE</font>    \n",
    "- <font color='lightblue'> DIVERTED         </font>       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OP_CARRIER              object\n",
      "OP_CARRIER_FL_NUM        int64\n",
      "ORIGIN                  object\n",
      "DEST                    object\n",
      "CRS_DEP_TIME             int64\n",
      "DEP_TIME               float64\n",
      "DEP_DELAY              float64\n",
      "TAXI_OUT               float64\n",
      "WHEELS_OFF             float64\n",
      "WHEELS_ON              float64\n",
      "TAXI_IN                float64\n",
      "CRS_ARR_TIME             int64\n",
      "ARR_TIME               float64\n",
      "ARR_DELAY              float64\n",
      "CRS_ELAPSED_TIME         int64\n",
      "ACTUAL_ELAPSED_TIME    float64\n",
      "AIR_TIME               float64\n",
      "DISTANCE                 int64\n",
      "CARRIER_DELAY          float64\n",
      "WEATHER_DELAY          float64\n",
      "NAS_DELAY              float64\n",
      "SECURITY_DELAY         float64\n",
      "LATE_AIRCRAFT_DELAY    float64\n",
      "MONTH                    int64\n",
      "DAY                      int64\n",
      "YEAR                     int64\n",
      "DAY_OF_WEEK              int64\n",
      "CANCELLED                 bool\n",
      "CANCELLATION_CODE       object\n",
      "DIVERTED                  bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(combined_flights.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\anaconda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\anaconda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_for_arrival_delay(combined_flights):\n",
    "    # Select features for prediction\n",
    "    features = [\n",
    "        'OP_CARRIER', \n",
    "        'ORIGIN', \n",
    "        'DEST', \n",
    "        'CRS_DEP_TIME', \n",
    "        'CRS_ARR_TIME', \n",
    "        'CRS_ELAPSED_TIME', \n",
    "        'DISTANCE', \n",
    "        'MONTH', \n",
    "        'DAY', \n",
    "        'YEAR', \n",
    "        'DAY_OF_WEEK'\n",
    "    ]\n",
    "    \n",
    "    # Create a copy of the dataframe\n",
    "    df = combined_flights[features + ['ARR_DELAY']].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Convert time columns to numeric minutes\n",
    "    def time_to_minutes(time_value):\n",
    "        if pd.isna(time_value):\n",
    "            return np.nan\n",
    "        \n",
    "        # If it's a numeric value like 1430\n",
    "        time_value = int(time_value)\n",
    "        hours = time_value // 100\n",
    "        minutes = time_value % 100\n",
    "        return hours * 60 + minutes\n",
    "    \n",
    "    df['CRS_DEP_TIME_MINUTES'] = df['CRS_DEP_TIME'].apply(time_to_minutes)\n",
    "    df['CRS_ARR_TIME_MINUTES'] = df['CRS_ARR_TIME'].apply(time_to_minutes)\n",
    "    \n",
    "    # Drop original time columns\n",
    "    df.drop(columns=['CRS_DEP_TIME', 'CRS_ARR_TIME'], inplace=True)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('ARR_DELAY', axis=1)\n",
    "    y = df['ARR_DELAY']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Example prediction\n",
    "def predict_arrival_delay(model, flight_data):\n",
    "    # Preprocess the input data similar to training data\n",
    "    processed_data = preprocess_for_arrival_delay(flight_data)[0]\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_delay = model.predict(processed_data)\n",
    "    \n",
    "    return predicted_delay\n",
    "\n",
    "# Optional: Feature importance\n",
    "def get_feature_importance(model):\n",
    "    # Get feature names directly from the preprocessor\n",
    "    preprocessor = model.named_steps['preprocessor']\n",
    "    \n",
    "    # Get numeric feature names\n",
    "    numeric_transformer = preprocessor.named_transformers_['num']\n",
    "    numeric_feature_names = numeric_transformer.get_feature_names_out().tolist()\n",
    "    \n",
    "    # Get categorical feature names\n",
    "    categorical_transformer = preprocessor.named_transformers_['cat']\n",
    "    categorical_feature_names = categorical_transformer.get_feature_names_out().tolist()\n",
    "    \n",
    "    # Combine feature names\n",
    "    feature_names = numeric_feature_names + categorical_feature_names\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.named_steps['regressor'].feature_importances_\n",
    "    \n",
    "    # Create a DataFrame of features and their importances\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arrival_delay_model(combined_flights):\n",
    "    # Preprocess data\n",
    "    X, y = preprocess_for_arrival_delay(combined_flights)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define preprocessing for numeric and categorical columns\n",
    "    numeric_features = [\n",
    "        'CRS_DEP_TIME_MINUTES', \n",
    "        'CRS_ARR_TIME_MINUTES', \n",
    "        'CRS_ELAPSED_TIME', \n",
    "        'DISTANCE', \n",
    "        'MONTH', \n",
    "        'DAY', \n",
    "        'YEAR', \n",
    "        'DAY_OF_WEEK'\n",
    "    ]\n",
    "    \n",
    "    categorical_features = [\n",
    "        'OP_CARRIER', \n",
    "        'ORIGIN', \n",
    "        'DEST'\n",
    "    ]\n",
    "    \n",
    "    # Create preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Create a pipeline\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Model Performance:\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f} minutes\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f} minutes\")\n",
    "    print(f\"R-squared Score: {r2:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arrival_delay_model_linear_regression(combined_flights):\n",
    "    # Preprocess data\n",
    "    X, y = preprocess_for_arrival_delay(combined_flights)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define preprocessing for numeric and categorical columns\n",
    "    numeric_features = [\n",
    "        'CRS_DEP_TIME_MINUTES', \n",
    "        'CRS_ARR_TIME_MINUTES', \n",
    "        'CRS_ELAPSED_TIME', \n",
    "        'DISTANCE', \n",
    "        'MONTH', \n",
    "        'DAY', \n",
    "        'YEAR', \n",
    "        'DAY_OF_WEEK'\n",
    "    ]\n",
    "    \n",
    "    categorical_features = [\n",
    "        'OP_CARRIER', \n",
    "        'ORIGIN', \n",
    "        'DEST'\n",
    "    ]\n",
    "    \n",
    "    # Create preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Create a pipeline with Linear Regression\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Linear Regression Model Performance:\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f} minutes\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f} minutes\")\n",
    "    print(f\"R-squared Score: {r2:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def train_arrival_delay_model_gbm(combined_flights):\n",
    "    # Preprocess data\n",
    "    X, y = preprocess_for_arrival_delay(combined_flights)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define preprocessing for numeric and categorical columns\n",
    "    numeric_features = [\n",
    "        'CRS_DEP_TIME_MINUTES', \n",
    "        'CRS_ARR_TIME_MINUTES', \n",
    "        'CRS_ELAPSED_TIME', \n",
    "        'DISTANCE', \n",
    "        'MONTH', \n",
    "        'DAY', \n",
    "        'YEAR', \n",
    "        'DAY_OF_WEEK'\n",
    "    ]\n",
    "    \n",
    "    categorical_features = [\n",
    "        'OP_CARRIER', \n",
    "        'ORIGIN', \n",
    "        'DEST'\n",
    "    ]\n",
    "    \n",
    "    # Create preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Create a pipeline with GradientBoostingRegressor\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Gradient Boosting Machine (GBM) Model Performance:\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f} minutes\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f} minutes\")\n",
    "    print(f\"R-squared Score: {r2:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in e:\\anaconda\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in e:\\anaconda\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in e:\\anaconda\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def train_arrival_delay_model_lightgbm(combined_flights):\n",
    "    \n",
    "    # Preprocess data\n",
    "    X, y = preprocess_for_arrival_delay(combined_flights)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define preprocessing for numeric and categorical columns\n",
    "    numeric_features = [\n",
    "        'CRS_DEP_TIME_MINUTES', \n",
    "        'CRS_ARR_TIME_MINUTES', \n",
    "        'CRS_ELAPSED_TIME', \n",
    "        'DISTANCE', \n",
    "        'MONTH', \n",
    "        'DAY', \n",
    "        'YEAR', \n",
    "        'DAY_OF_WEEK'\n",
    "    ]\n",
    "    categorical_features = [\n",
    "        'OP_CARRIER', \n",
    "        'ORIGIN', \n",
    "        'DEST'\n",
    "    ]\n",
    "\n",
    "    # Create a preprocessor\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Create a pipeline with LightGBM\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', lgb.LGBMRegressor(verbosity=-1, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Perform hyperparameter tuning with RandomizedSearchCV\n",
    "    param_grid = {\n",
    "        'regressor__num_leaves': [31, 50, 100],\n",
    "        'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'regressor__n_estimators': [100, 200, 300],\n",
    "        'regressor__max_depth': [5, 10, 15],\n",
    "        'regressor__colsample_bytree': [0.7, 0.8, 0.9]\n",
    "    }\n",
    "    \n",
    "    # Initialize RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=100,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train using RandomizedSearchCV\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Extract the best model\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"LightGBM Model Performance with Tuning:\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f} minutes\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f} minutes\")\n",
    "    print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "    return best_model, random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual delay : 67    10.0\n",
      "Name: ARR_DELAY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "chosen_flight = 67\n",
    "single_flight = combined_flights.iloc[[chosen_flight]]\n",
    "print(f\"Actual delay : {single_flight['ARR_DELAY']}\")\n",
    "\n",
    "# Define feature lists before model training\n",
    "numeric_features = ['DISTANCE', 'CRS_ELAPSED_TIME', 'DEP_TIME', 'ARR_TIME']\n",
    "categorical_features = ['OP_CARRIER', 'ORIGIN', 'DEST', 'DAY_OF_WEEK', 'MONTH']\n",
    "\n",
    "combined_flights_2 = combined_flights.sample(frac=0.01, random_state=52)\n",
    "\n",
    "## RFR prediction.\n",
    "arrival_delay_model = train_arrival_delay_model(combined_flights_2)\n",
    "predicted_delay = predict_arrival_delay(arrival_delay_model, single_flight)\n",
    "print(\"Predicted Delay (RFR):\", predicted_delay)\n",
    "\n",
    "# Get feature importances\n",
    "# feature_importances = get_feature_importance(arrival_delay_model)\n",
    "# print(feature_importances.head(10))  # Top 10 most important features\n",
    "\n",
    "\n",
    "## LINEAR REGRESSION prediction.\n",
    "#print(\"---\")\n",
    "#arrival_delay_model_2 = train_arrival_delay_model_linear_regression(combined_flights_2)\n",
    "#predicted_delay = predict_arrival_delay(arrival_delay_model_2, single_flight)\n",
    "#print(\"Predicted Delay (LR):\", predicted_delay)\n",
    "\n",
    "\n",
    "## GBM prediction.\n",
    "print(\"---\")\n",
    "#arrival_delay_model_3 = train_arrival_delay_model_gbm(combined_flights_2)\n",
    "#predicted_delay = predict_arrival_delay(arrival_delay_model_3, single_flight)\n",
    "#print(\"Predicted Delay (GBM):\", predicted_delay)\n",
    "\n",
    "\n",
    "## lightGBM prediction.\n",
    "#arrival_delay_model_4 = train_arrival_delay_model_lightgbm(combined_flights_2)[0]\n",
    "#predicted_delay = predict_arrival_delay(arrival_delay_model_4, single_flight)\n",
    "#print(\"Predicted Delay (lightGBM):\", predicted_delay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    "Ideas to look into: \n",
    "- **Using only the data we know before the flight, to predict something about the flight**\n",
    "- **Using data about the flight, to predict something about the delays, how long is some delay based on whole delay**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
